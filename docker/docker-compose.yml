# Docker Compose configuration for all services
# Website repository is now public - deployment will work
services:
  # Reverse Proxy - Routes traffic to different services
  nginx:
    image: nginx:alpine
    container_name: main_nginx
    restart: always
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/sites-enabled:/etc/nginx/sites-enabled:ro
      - ./nginx/snippets:/etc/nginx/snippets:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - nginx_logs:/var/log/nginx
      - certbot_webroot:/var/www/certbot:ro
    networks:
      - proxy_network
    depends_on:
      - ghost
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Ghost CMS - Main Website Management System
  ghost:
    image: ghost:5.119-alpine
    container_name: ghost_cms
    restart: always
    expose:
      - "2368"
    environment:
      url: https://www.goplasmatic.io
      admin__url: https://webadmin.goplasmatic.io
      NODE_ENV: production
      database__client: mysql
      database__connection__host: ghost_db
      database__connection__user: ${GHOST_MYSQL_USER}
      database__connection__password: ${GHOST_MYSQL_PASSWORD}
      database__connection__database: ${GHOST_MYSQL_DATABASE}
      mail__transport: SMTP
      mail__options__host: smtp.mailgun.org
      mail__options__port: 587
      mail__options__secure: false
      mail__options__auth__user: ${MAIL_USER}
      mail__options__auth__pass: ${MAIL_PASS}
      mail__from: ${MAIL_FROM}
      paths__contentPath: /var/lib/ghost/content
    volumes:
      - ../applications/ghost/data/content:/var/lib/ghost/content
    networks:
      - proxy_network
      - ghost_network
    depends_on:
      ghost_db:
        condition: service_healthy

  # Ghost Database
  ghost_db:
    image: mysql:8.0
    container_name: ghost_db
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: ${GHOST_MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: ${GHOST_MYSQL_DATABASE}
      MYSQL_USER: ${GHOST_MYSQL_USER}
      MYSQL_PASSWORD: ${GHOST_MYSQL_PASSWORD}
    volumes:
      - ghost_mysql_data:/var/lib/mysql
    networks:
      - ghost_network
    command: --default-authentication-plugin=mysql_native_password
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-p${GHOST_MYSQL_ROOT_PASSWORD}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # MongoDB database for Reframe audit logging
  reframe_db:
    image: mongo:latest
    container_name: reframe_db
    restart: always
    expose:
      - "27017"
    volumes:
      - reframe_mongodb_data:/data/db
    environment:
      - MONGO_INITDB_DATABASE=reframe
    networks:
      - reframe_network
    healthcheck:
      test: ["CMD", "mongosh", "--quiet", "--eval", "db.adminCommand('ping').ok"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s

  # Reframe API - SWIFT Message Transformation Engine (Using ACR image)
  reframe:
    image: ${ACR_URL}/reframe:latest
    container_name: reframe_api
    restart: always
    pull_policy: always  # Always pull latest image
    expose:
      - "3000"
    networks:
      - proxy_network
      - reframe_network
    environment:
      - RUST_LOG=info
      - REFRAME_PORT=3000
      - API_SERVER_URL=https://reframeapi.goplasmatic.io
      # Package path (should be baked into the image during build)
      - REFRAME_PACKAGE_PATH=/packages/swift-cbpr
      # Database configuration
      - DB_TYPE=mongodb
      - DB_URI=mongodb://reframe_db:27017
      - DB_NAME=reframe
      - DB_COLLECTION=reframe_audit
    depends_on:
      reframe_db:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 3s
      start_period: 70s  # Reframe needs ~60s to initialize before /health endpoint is available
      retries: 3

  # Sandbox Website - Testing Environment (Using ACR image)
  sandbox:
    image: ${ACR_URL}/sandbox:latest
    container_name: sandbox_website
    restart: always
    pull_policy: always  # Always pull latest image
    expose:
      - "3000"
    networks:
      - proxy_network
    environment:
      - NODE_ENV=production
      - REFRAME_API_URL=https://reframeapi.goplasmatic.io
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/"]
      interval: 30s
      timeout: 3s
      start_period: 30s
      retries: 3

  # Monitoring with Prometheus
  prometheus:
    image: prom/prometheus:v2.54.1
    container_name: prometheus
    restart: always
    expose:
      - "9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    networks:
      - monitoring_network
      - proxy_network
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'

  # Grafana for visualization
  grafana:
    image: grafana/grafana:11.4.0
    container_name: grafana
    restart: always
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_SERVER_ROOT_URL=https://grafana.goplasmatic.io
      - GF_SERVER_SERVE_FROM_SUB_PATH=false
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
    networks:
      - monitoring_network
      - proxy_network
    depends_on:
      - prometheus

  # Node Exporter for system metrics
  node_exporter:
    image: prom/node-exporter:v1.8.2
    container_name: node_exporter
    restart: always
    expose:
      - "9100"
    networks:
      - monitoring_network
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'

  # cAdvisor for Docker container metrics
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.51.0
    container_name: cadvisor
    restart: always
    expose:
      - "8080"
    networks:
      - monitoring_network
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    devices:
      - /dev/kmsg:/dev/kmsg

  # Backup service - commented out as backup script was moved to /scripts/backup.sh
  # backup:
  #   image: alpine:latest
  #   container_name: backup_service
  #   restart: always
  #   environment:
  #     BACKUP_RETENTION_DAYS: ${BACKUP_RETENTION_DAYS:-7}
  #   volumes:
  #     - ../applications:/applications:ro
  #     - ghost_mysql_data:/mysql/ghost:ro
  #     - ./backups:/backups
  #     - ./scripts/backup-multi.sh:/backup.sh:ro
  #   entrypoint: /bin/sh -c "chmod +x /backup.sh && echo '0 2 * * * /backup.sh' | crontab - && crond -f -d 8"
  #   networks:
  #     - backup_network

volumes:
  nginx_logs:
    driver: local
  ghost_mysql_data:
    driver: local
  reframe_mongodb_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  certbot_webroot:
    driver: local

networks:
  proxy_network:
    driver: bridge
    name: proxy_network
  ghost_network:
    driver: bridge
    internal: true
  reframe_network:
    driver: bridge
    internal: true
  monitoring_network:
    driver: bridge
    internal: true
  backup_network:
    driver: bridge
    internal: true